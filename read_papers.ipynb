{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/llc/Downloads/graphen/paper\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function which helps to convert the file to pdf format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_pdf_to_txt(path=\"./\"):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    maxpages = 40\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = os.listdir('./doc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####ADD another chunk to read the additional papers####\n",
    "\n",
    "document = []\n",
    "for paper in papers:\n",
    "    dir = './doc/' + paper\n",
    "    document.append(convert_pdf_to_txt(dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['page16', 'page20', 'page27', 'page18', 'page26', 'page19', 'page21', 'page17', 'page24', 'page23', 'page22', 'page25']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "add_paperfiles = os.listdir('./doc1/')\n",
    "fil_paperfiles = []\n",
    "for fil in add_paperfiles:\n",
    "    if \"page\" in fil:\n",
    "        fil_paperfiles.append(fil)\n",
    "print(fil_paperfiles)\n",
    "for fil in fil_paperfiles:\n",
    "    for paperfiles in os.listdir(str(\"./doc1/\")+str(fil)):\n",
    "        document.append(convert_pdf_to_txt(str(\"./doc1/\")+str(fil)+\"/\"+str(paperfiles)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Problems-of-variable-biomarker-evaluation-in-stratified-medicine-_2016_Lung-.pdf'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir(\"./\"))\n",
    "papers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2286\n"
     ]
    }
   ],
   "source": [
    "print(len(document))\n",
    "np.savez(\"all_the_papers\", text=document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2286\n"
     ]
    }
   ],
   "source": [
    "document=np.load(\"all_the_papers.npz\")[\"text\"]\n",
    "print(len(document))\n",
    "for i in range(len(document)):\n",
    "    document[i] = document[i].replace(\"\\\\n\",\"\")\n",
    "processed = document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the papers are already formatted. We are going to locate the gene names and extract three word after the first gene name appears and three words before the second gene name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geneweb=\"https://www.genome.jp/dbget-bin/get_linkdb?-t+9+path:map05223\"\n",
    "x = urllib.request.urlopen(geneweb)\n",
    "text=x.read()\n",
    "text=str(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The items in dictionary d are the genes names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regex = 'K[0-9]{5}</a>'\n",
    "result=re.finditer(regex,text)\n",
    "indices = [m.start(0) for m in result]\n",
    "d = dict()\n",
    "for i in indices:\n",
    "    s1 = text[i:i+6]\n",
    "    s2 = text[i+25:i+text[i:].find(';')]\n",
    "    d[s1] = s2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "red={value:key for key,value in d.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys in dict1 are the gene names in papers.\n",
    "We are going to locate their positions in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict1 = {}\n",
    "for ke,va in red.items():\n",
    "    ke=ke.split(\", \")\n",
    "    for i in range(len(ke)):\n",
    "        dict1[ke[i]] = va\n",
    "\n",
    "#We need to add more gene names to this dictionary, because they appear slight differently in papers.\n",
    "dict1['K-RAS']='K07827'\n",
    "dict1['N-RAS']='K07827'\n",
    "dict1['RAS']='K07827'\n",
    "dict1['H-RAS']='K02833'\n",
    "dict1['HER-2'] = 'K05083'\n",
    "dict1['PLCG-1'] = 'K01116'\n",
    "dict1['PLCG-2'] = 'K05859'\n",
    "dict1['STAT'] = 'K11224'\n",
    "dict1['MEK'] = 'K04368'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next chunk below, we have found another dictionary from https://www.genecards.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('GeneCards-SearchResults.csv')\n",
    "gs = data['Gene Symbol']\n",
    "des = data['Description']\n",
    "des_len = len(des)\n",
    "des_1 = []\n",
    "for i in range (des_len):\n",
    "    word = str(des[i]).split(\" \")[0]\n",
    "    des_1.append(word)\n",
    "gene_dict = {}\n",
    "for i in range (des_len):\n",
    "    gene_dict[gs[i]] = des_1[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of gene names we are using is 16424\n"
     ]
    }
   ],
   "source": [
    "#WE have two dicts one is from gene cards.com we downloaded the csv file there. \n",
    "#We used webscraping techniques to download the genes related with non-small cell lung cancer\n",
    "def merge_dicts(x, y):\n",
    "    z = x.copy()  \n",
    "    z.update(y)\n",
    "    return z\n",
    "merged_dict=merge_dicts(dict1,gene_dict)\n",
    "print(\"Total number of gene names we are using is \"+ str(len(merged_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<_sre.SRE_Match object; span=(38670, 38673), match='ALK'>, <_sre.SRE_Match object; span=(2759, 2762), match='RAS'>, <_sre.SRE_Match object; span=(9966, 9970), match='STAT'>]\n"
     ]
    }
   ],
   "source": [
    "def locate_genes(text):\n",
    "    orders=[]\n",
    "    upp=text.upper()\n",
    "    for gene in dict1.keys():\n",
    "        ls=re.search(gene,upp)\n",
    "        if ls is not None:\n",
    "            orders.append(ls)\n",
    "    return orders\n",
    "print(locate_genes(processed[0]))\n",
    "\n",
    "def Collection_of_pdfs(path=\"../doc\"):\n",
    "    checked = []\n",
    "    for pdf_file in os.listdir(path):\n",
    "        if pdf_file[-4:] == \".pdf\":\n",
    "            checked.append(pdf_file)\n",
    "    return checked\n",
    "#print(Collection_of_pdfs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict2 = {}\n",
    "for key, value in merged_dict.items():\n",
    "    dict2[key] = value\n",
    "for key, value in merged_dict.items():\n",
    "    regex = r'[A-Z]{2,}'\n",
    "    regex_match = re.findall(regex, key)\n",
    "    if regex_match != []:\n",
    "        dict2[regex_match[0]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_sentence(paper):\n",
    "    paper_list = paper.split('.')\n",
    "    res = []\n",
    "\n",
    "    for sentence in paper_list:\n",
    "        gene=[]\n",
    "        count = 0\n",
    "        word_list = sentence.split(' ')\n",
    "        word_set = set()\n",
    "\n",
    "        for word in word_list:\n",
    "            word = word.upper()\n",
    "            if word in dict2 and word not in word_set:\n",
    "                count += 1\n",
    "                gene.append(word)\n",
    "                word_set.add(word)\n",
    "                \n",
    "        if count >=2:\n",
    "            res.append([sentence, gene[0], gene[1]])\n",
    "            #first_gene.append(gene[0])\n",
    "            #second_gene.append(gene[1])\n",
    "            #sentence_protein.append(sentence)\n",
    "    return res\n",
    "    #return sentence_protein, first_gene, second_gene\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Append all the sentences contains the relationship of genes to sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence=[]\n",
    "for papers in processed:\n",
    "    sentence += locate_sentence(papers)\n",
    "df_gene=pd.concat([pd.DataFrame(sentence[i]).T for i in range(len(sentence))], ignore_index=True)\n",
    "df_gene.columns=[\"Sentence\",\"Gene1\",\"Gene2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Gene1</th>\n",
       "      <th>Gene2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nicholson e,   Lucinda   Billingham a\\na Ca...</td>\n",
       "      <td>MRC</td>\n",
       "      <td>NHS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As   a  case   study   we   evaluated   how...</td>\n",
       "      <td>AS</td>\n",
       "      <td>WAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In   ﬁve   studies   ERCC1   use   was   pl...</td>\n",
       "      <td>ERCC1</td>\n",
       "      <td>USE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nConclusions:   We   found   large   variatio...</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>ERCC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A  review  of  published  papers  investigat...</td>\n",
       "      <td>WAS</td>\n",
       "      <td>LARGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Gene1  Gene2\n",
       "0     Nicholson e,   Lucinda   Billingham a\\na Ca...    MRC    NHS\n",
       "1     As   a  case   study   we   evaluated   how...     AS    WAS\n",
       "2     In   ﬁve   studies   ERCC1   use   was   pl...  ERCC1    USE\n",
       "3  \\nConclusions:   We   found   large   variatio...  LARGE  ERCC1\n",
       "4    A  review  of  published  papers  investigat...    WAS  LARGE"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gene.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65049, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gene.shape\n",
    "#There are 67594 sentences in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_relations(paper):\n",
    "    paper_list = paper.split('.')\n",
    "    res = []\n",
    "\n",
    "    for sentence in paper_list:\n",
    "        gene=[]\n",
    "        count = 0\n",
    "        word_list = sentence.split(' ')\n",
    "        word_set = set()\n",
    "\n",
    "        for word in word_list:\n",
    "            word = word.upper()\n",
    "            if word in dict2 and word not in word_set:\n",
    "                count += 1\n",
    "                gene.append(word)\n",
    "                word_set.add(word)\n",
    "                \n",
    "        if count >=2:\n",
    "            res.append([sentence[sentence.find(gene[0]+len(gene[0])),sentence.find(gene[1])], gene[0], gene[1]])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relations=[]\n",
    "for papers in processed:\n",
    "    relations += locate_sentence(papers)\n",
    "df_relations=pd.concat([pd.DataFrame(relations[i]).T for i in range(len(relations))], ignore_index=True)\n",
    "df_relations.columns=[\"Relations\",\"Gene1\",\"Gene2\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Then we use the fasttext to do the embeding for all the papers.\n",
    "#The code below is what I used to create a Dataframe and label the sentences manually to indicate our clustering result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
